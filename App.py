import streamlit as st
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split
from imblearn.combine import SMOTETomek
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score, roc_curve, classification_report
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import warnings

# ==============================================================================
# CONFIGURATION ET NETTOYAGE
# ==============================================================================
warnings.filterwarnings('ignore')
st.set_page_config(
    page_title="Analyse Dr√©panocytose - Segmentation & Pr√©diction",
    layout="wide"
)

# --- Fichiers d'entr√©e (Doivent √™tre pr√©sents dans le d√©p√¥t) ---
CLUSTER_DATA_PATH = "segmentation.xlsx"
PREDICT_DATA_PATH = "fichier_nettoye.xlsx"

# --- Chemins des mod√®les sauvegard√©s (Doivent √™tre cr√©√©s AVANT le d√©ploiement) ---
MODEL_PATH = "random_forest_model.pkl"
SCALER_PATH = "scaler.pkl"
FEATURES_PATH = "features.pkl"

# --- Constantes pour la pr√©diction (doivent correspondre √† vos r√©sultats) ---
# **REMPLACER CES VALEURS par les r√©sultats de votre script d'entra√Ænement (step 11/13)**
BEST_MODEL_NAME = "Random Forest"
BEST_THRESHOLD = 0.56 # Remplacer par votre seuil optimal
SUMMARY_DF_RAW = {
    "Mod√®le": ["Random Forest", "LightGBM", "Decision Tree", "SVM"],
    "AUC-ROC": [0.965, 0.958, 0.880, 0.945], # Exemple : REMPLACER PAR VOS VRAIES VALEURS
    "Seuil optimal": [0.450, 0.520, 0.500, 0.510] # Exemple : REMPLACER PAR VOS VRAIES VALEURS
}
summary_df = pd.DataFrame(SUMMARY_DF_RAW).sort_values(by="AUC-ROC", ascending=False).reset_index(drop=True)

# --- Variables quantitatives pour Standardisation (doivent √™tre les m√™mes dans les deux parties) ---
QUANTITATIVE_VARS_PREDICT = [
    '√Çge de d√©but des signes (en mois)', 'GR (/mm3)', 'GB (/mm3)',
    '√Çge du debut d etude en mois (en janvier 2023)', 'VGM (fl/u3)',
    'HB (g/dl)', 'Nbre de GB (/mm3)', 'PLT (/mm3)', 'Nbre de PLT (/mm3)',
    'TCMH (g/dl)', "Nbre d'hospitalisations avant 2017",
    "Nbre d'hospitalisations entre 2017 et 2023",
    'Nbre de transfusion avant 2017', 'Nbre de transfusion Entre 2017 et 2023',
    'CRP Si positive (Valeur)', "Taux d'Hb (g/dL)", "% d'Hb S", "% d'Hb F"
]

# ==============================================================================
# FONCTIONS CACH√âES (CLUSTERING)
# ==============================================================================

@st.cache_data(show_spinner="Nettoyage des donn√©es et calcul du clustering...")
def preparer_et_calculer_coude(chemin_fichier):
    # --- 1. Chargement et S√©lection ---
    try:
        df = pd.read_excel(chemin_fichier)
    except FileNotFoundError:
        return None, None, None, "Fichier de clustering non trouv√©."

    df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)
    
    # Liste de variables (du script de clustering)
    variables_selected = [
        "√Çge du debut d etude en mois (en janvier 2023)", "Taux d'Hb (g/dL)", "% d'Hb F", "% d'Hb S", "% d'HB C",
        "Nbre de GB (/mm3)", "% d'HB A2", "Nbre de PLT (/mm3)", "√Çge de d√©but des signes (en mois)",
        "√Çge de d√©couverte de la dr√©panocytose (en mois)", "Nbre d'hospitalisations avant 2017",
        "Nbre d'hospitalisations entre 2017 et 2023", "Nbre de transfusion avant 2017",
        "Nbre de transfusion Entre 2017 et 2023", "HDJ",
        "Sexe", "Origine G√©ographique", "Parents Salari√©s", "PEV Complet", 
        "Vaccin contre pneumocoque", "Vaccin contre m√©ningocoque", "Vaccin contre Les salmonelles",
        "L'hydroxyur√©e", "Echange transfusionnelle", "Prise en charge", "Prophylaxie √† la p√©nicilline",
        "CVO", "An√©mie", "AVC", "STA", "Priapisme", "Infections", "Ict√®re", "Type de dr√©panocytose",
    ]
    
    df_selected = df[variables_selected].fillna(0).copy() 
    
    # --- 2. Encodage (Identique √† votre script de clustering) ---
    binary_mappings = {
        "Sexe": {"Masculin": 1, "F√©minin": 0, "M": 1, "F": 0}, "Parents Salari√©s": {"OUI": 1, "NON": 0},
        "PEV Complet": {"OUI": 1, "NON": 0}, "Vaccin contre pneumocoque": {"OUI": 1, "NON": 0},
        "Vaccin contre m√©ningocoque": {"OUI": 1, "NON": 0}, "Vaccin contre Les salmonelles": {"OUI": 1, "NON": 0},
        "L'hydroxyur√©e": {"OUI": 1, "NON": 0}, "Echange transfusionnelle": {"OUI": 1, "NON": 0},
        "Prophylaxie √† la p√©nicilline": {"OUI": 1, "NON": 0}, "CVO": {"OUI": 1, "NON": 0},
        "An√©mie": {"OUI": 1, "NON": 0}, "AVC": {"OUI": 1, "NON": 0}, "STA": {"OUI": 1, "NON": 0},
        "Priapisme": {"OUI": 1, "NON": 0}, "Infections": {"OUI": 1, "NON": 0}, "Ict√®re": {"OUI": 1, "NON": 0},
    }
    df_selected.replace(binary_mappings, inplace=True)
    df_selected = pd.get_dummies(df_selected, columns=["Origine G√©ographique"], drop_first=False)
    df_selected = pd.get_dummies(df_selected, columns=["Prise en charge"], drop_first=True)
    df_selected = pd.get_dummies(df_selected, columns=["Type de dr√©panocytose"], drop_first=False)

    # --- 3. Standardisation ---
    quantitative_vars = [
        "√Çge du debut d etude en mois (en janvier 2023)", "Taux d'Hb (g/dL)", "% d'Hb F", "% d'Hb S", "% d'HB C",
        "Nbre de GB (/mm3)", "% d'HB A2", "Nbre de PLT (/mm3)", "√Çge de d√©but des signes (en mois)",
        "√Çge de d√©couverte de la dr√©panocytose (en mois)", "Nbre d'hospitalisations avant 2017",
        "Nbre d'hospitalisations entre 2017 et 2023", "Nbre de transfusion avant 2017",
        "Nbre de transfusion Entre 2017 et 2023", "HDJ"
    ]
    scaler = StandardScaler()
    df_selected[quantitative_vars] = scaler.fit_transform(df_selected[quantitative_vars].fillna(0))
    df_final = df_selected.dropna(axis=1) # Supprime les colonnes totalement NaN apr√®s OHE/clean
    
    if df_final.empty or df_final.shape[1] == 0:
        return None, None, None, "Le DataFrame final est vide apr√®s le pr√©traitement."

    # --- 4. Graphe du coude ---
    inertia = []
    K_range = range(1, 11)
    for k in K_range:
        kmeans_test = KMeans(n_clusters=k, random_state=42, n_init=10)
        kmeans_test.fit(df_final)
        inertia.append(kmeans_test.inertia_)

    fig_coude, ax = plt.subplots(figsize=(8, 5))
    ax.plot(K_range, inertia, marker='o')
    ax.set_xlabel('Nombre de clusters (k)')
    ax.set_ylabel('Inertia (SSE)')
    ax.set_title('Graphe du coude pour KMeans')
    ax.set_xticks(K_range)
    ax.grid(True)
    
    return df_final, fig_coude, df, None

# ==============================================================================
# FONCTIONS CACH√âES (PR√âDICTION)
# ==============================================================================

@st.cache_resource
def load_predictive_resources():
    """Charge le meilleur mod√®le, le scaler et les features pour la pr√©diction."""
    try:
        model = joblib.load(MODEL_PATH)
        scaler = joblib.load(SCALER_PATH)
        features = joblib.load(FEATURES_PATH)
        return model, scaler, features
    except FileNotFoundError as e:
        return None, None, None
    except Exception as e:
        return None, None, None

model_loaded, scaler_loaded, features_loaded = load_predictive_resources()

def prepare_and_predict(input_data):
    """Pr√©pare les donn√©es et retourne la probabilit√©/classe."""
    new_data = pd.DataFrame([input_data])
    
    # 1. Ajouter les colonnes manquantes (OHE) et s'assurer du bon ordre
    for col in features_loaded:
        if col not in new_data.columns:
            new_data[col] = 0
            
    new_data = new_data[features_loaded]
    
    # 2. Standardisation
    new_data_scaled = new_data.copy()
    cols_to_scale = [col for col in QUANTITATIVE_VARS_PREDICT if col in new_data_scaled.columns]
    
    if not cols_to_scale or scaler_loaded is None:
        return None, None

    new_data_scaled[cols_to_scale] = scaler_loaded.transform(new_data[cols_to_scale])

    # 3. Pr√©diction
    pred_proba = model_loaded.predict_proba(new_data_scaled)[:, 1][0]
    pred_class = (pred_proba >= BEST_THRESHOLD).astype(int)
    
    return pred_proba, pred_class

# ==============================================================================
# INTERFACE UTILISATEUR STREAMLIT
# ==============================================================================

st.title("Projet Data Science : Dr√©panocytose")
st.markdown("Analyse de Segmentation et Mod√®le Pr√©dictif du Risque de Complications")

tab_cluster, tab_predict_eval, tab_predict_interface = st.tabs([
    "üìä Segmentation K-Means", 
    "üìà √âvaluation du Mod√®le", 
    "üß™ Interface de Pr√©diction"
])

# --------------------------------------------------------------------------
# ONGLET 1 : CLUSTERING
# --------------------------------------------------------------------------
with tab_cluster:
    st.header("Analyse de Segmentation (Clustering K-Means)")
    df_final, fig_coude, df_original, error_msg = preparer_et_calculer_coude(CLUSTER_DATA_PATH)
    
    if error_msg:
        st.error(error_msg)
    elif df_final is None:
        st.warning("V√©rifiez la structure de votre fichier 'segmentation.xlsx'.")
    else:
        st.subheader("√âtape 1 : D√©termination du Nombre Optimal de Clusters (K)")
        col_coude, col_k_choice = st.columns([2, 1])

        with col_coude:
            st.pyplot(fig_coude)
            st.caption("Le 'coude' sugg√®re le nombre optimal de clusters.")

        with col_k_choice:
            K_optimal = st.slider("Choisissez le nombre de clusters (K) :", min_value=2, max_value=10, value=3, step=1)
            st.info(f"Mod√®le entra√Æn√© avec **K = {K_optimal}** clusters.")

        # Ex√©cution de K-Means final
        kmeans = KMeans(n_clusters=K_optimal, random_state=42, n_init=10)
        clusters = kmeans.fit_predict(df_final)

        df_clusters = df_original.copy()
        df_clusters['Cluster'] = clusters

        st.subheader(f"√âtape 2 : Profils des {K_optimal} Clusters")
        
        # Calcul des m√©triques cl√©s par cluster pour l'interpr√©tation
        df_summary = df_clusters.groupby('Cluster').agg({
            '√Çge du debut d etude en mois (en janvier 2023)': 'mean',
            "Taux d'Hb (g/dL)": 'mean',
            "Nbre d'hospitalisations entre 2017 et 2023": 'mean',
            "L'hydroxyur√©e": 'mean', # Proportion de Oui
            "Sexe": 'mean' # Proportion de Masculin
        })
        df_summary['Taille'] = df_clusters['Cluster'].value_counts().sort_index()

        st.dataframe(df_summary.rename(columns={"L'hydroxyur√©e": "Prop. Hydroxyur√©e (1=Oui)", "Sexe": "Prop. Masculin (1=M)"}), use_container_width=True)

        st.subheader("√âtape 3 : Visualisation des Clusters (PCA)")
        pca = PCA(n_components=2)
        principal_components = pca.fit_transform(df_final)
        df_pca = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])
        df_pca['Cluster'] = clusters

        fig_pca, ax_pca = plt.subplots(figsize=(10, 8))
        scatter = ax_pca.scatter(df_pca['PC1'], df_pca['PC2'], c=df_pca['Cluster'], cmap='viridis', s=50, alpha=0.7)
        ax_pca.set_xlabel(f'Composante Principale 1 ({pca.explained_variance_ratio_[0]*100:.1f}%)')
        ax_pca.set_ylabel(f'Composante Principale 2 ({pca.explained_variance_ratio_[1]*100:.1f}%)')
        ax_pca.set_title(f'Visualisation des {K_optimal} Clusters (K-Means + PCA)')
        ax_pca.legend(*scatter.legend_elements(), title="Clusters")
        st.pyplot(fig_pca)

# --------------------------------------------------------------------------
# ONGLET 2 : √âVALUATION DU MOD√àLE
# --------------------------------------------------------------------------
with tab_predict_eval:
    st.header("√âvaluation des Mod√®les de Pr√©diction (√âvolution = Complications)")
    
    if model_loaded is None:
        st.error("Les fichiers du mod√®le (Random Forest) n'ont pas √©t√© trouv√©s. Veuillez ex√©cuter le script d'entra√Ænement une fois pour g√©n√©rer les fichiers `.pkl`.")
    else:
        st.subheader("Tableau de Synth√®se des Performances")
        st.dataframe(
            summary_df.set_index('Mod√®le').style.background_gradient(subset=["AUC-ROC", "Accuracy"], cmap='Blues'),
            use_container_width=True
        )
        
        st.subheader(f"Comparaison de l'AUC-ROC (Meilleur Mod√®le : {BEST_MODEL_NAME})")
        fig_auc, ax_auc = plt.subplots(figsize=(10,6))
        sns.barplot(x="Mod√®le", y="AUC-ROC", data=summary_df, ax=ax_auc)
        ax_auc.set_title("Comparaison des mod√®les selon l'AUC-ROC")
        ax_auc.set_ylim(0,1)
        st.pyplot(fig_auc)

# --------------------------------------------------------------------------
# ONGLET 3 : PR√âDICTION INTERACTIVE
# --------------------------------------------------------------------------
with tab_predict_interface:
    st.header("Simulateur de Risque de Complications")
    
    if model_loaded is None:
        st.warning("Impossible d'effectuer des pr√©dictions sans les fichiers du mod√®le.")
    else:
        st.markdown(f"**Mod√®le utilis√© : {BEST_MODEL_NAME}** (Seuil optimal : **{BEST_THRESHOLD:.3f}**)")
        st.info("Entrez les donn√©es du patient pour obtenir une estimation du risque d'√©volution vers des complications.")

        # --- Saisie des donn√©es ---
        input_data = {}
        
        st.subheader("Param√®tres Cl√©s du Patient")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            input_data['√Çge du debut d etude en mois (en janvier 2023)'] = st.number_input("√Çge (mois)", min_value=1, value=24)
            input_data["Taux d'Hb (g/dL)"] = st.number_input("Taux d'Hb (g/dL)", min_value=1.0, max_value=20.0, value=9.5, format="%.2f")
            input_data["% d'Hb S"] = st.number_input("% d'Hb S", min_value=0.0, max_value=100.0, value=85.0, format="%.1f")
            
        with col2:
            input_data["Nbre d'hospitalisations entre 2017 et 2023"] = st.number_input("Nbre d'Hospitalisations (2017-2023)", min_value=0, value=0)
            input_data['CRP Si positive (Valeur)'] = st.number_input("CRP (mg/L)", min_value=0.0, max_value=500.0, value=5.0, format="%.1f")
            input_data['P√¢leur'] = st.selectbox("P√¢leur (Oui=1/Non=0)", options=[1, 0], format_func=lambda x: 'Oui' if x == 1 else 'Non')
            
        with col3:
            # Saisie de la cat√©gorie de diagnostic (pour l'OHE)
            diag_cat = st.selectbox("Diagnostic Cat√©goris√©", options=['Autres', 'CVO', 'Infections', 'AVC', 'STA', 'An√©mie'])
            # Cr√©ation des colonnes OHE n√©cessaires
            for cat in ['CVO', 'Infections', 'AVC', 'STA', 'An√©mie']:
                input_data[f'Diagnostic Cat√©goris√©_{cat}'] = 1 if diag_cat == cat else 0

            # Saisie d'un mois (pour l'OHE)
            mois_input = st.selectbox("Mois de l'Urgence (1=Janvier...)", options=list(range(1, 13)))
            for m in range(2, 13):
                input_data[f'Mois_{m}'] = 1 if mois_input == m else 0
            
            input_data['Prise en charge Hospitalisation'] = st.selectbox("Hospitalisation requise", options=[1, 0], format_func=lambda x: 'Oui' if x == 1 else 'Non')

        st.markdown("---")
        
        if st.button("√âvaluer le Risque", type="primary"):
            
            # --- Ajout des variables non demand√©es (avec valeur par d√©faut 0) ---
            final_input_data = {}
            for feature in features_loaded:
                # Priorit√© aux valeurs saisies par l'utilisateur
                if feature in input_data and not isinstance(input_data[feature], str):
                    final_input_data[feature] = input_data[feature]
                elif feature.startswith('Diagnostic Cat√©goris√©_') and feature in input_data:
                     final_input_data[feature] = input_data[feature]
                elif feature.startswith('Mois_') and feature in input_data:
                     final_input_data[feature] = input_data[feature]
                else:
                    # D√©faut pour les variables binaires/quantitatives non saisies
                    final_input_data[feature] = 0

            prob, classe = prepare_and_predict(final_input_data)
            
            if prob is not None:
                col_res1, col_res2, col_res3 = st.columns(3)
                
                with col_res1:
                    st.metric(label="Probabilit√© de Complications", value=f"{prob*100:.1f}%")
                    
                with col_res2:
                    if classe == 1:
                        st.error("R√©sultat : **RISQUE √âLEV√â DE COMPLICATIONS**", icon="‚ö†Ô∏è")
                    else:
                        st.success("R√©sultat : **√âVOLUTION FAVORABLE PR√âDITE**", icon="‚úÖ")
                        
                with col_res3:
                    st.metric(label="Seuil de D√©cision", value=f"{BEST_THRESHOLD:.3f}")

